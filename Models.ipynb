{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "--- \n",
    "# Model Fitting and Techniques \n",
    "***\n",
    "\n",
    "The overall goal of this section is to try various techniques to fit a model for mortality rate using food consumption data.  First, we will find a null model, representing the 'average' input and representing a baseline estimation that we will then improve upon. Then we will fit a multilinear regression to all of the predictors (all livestock and all crop predictors), and find a cross-validated $R^2$ for this naive model. Next, we will try more advanced techniques such as Lasso, Ridge, Step-wise, and Regression Trees to improve this model. \n",
    "\n",
    "To summarize, our null model achieved a cross-validated $R^2$ score of 0 for all three diseases. Our naive model achieved a cross-validated score of $ $ for diabetes, $ $ for cancer, and $ $ for cardiovascular diseases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Model\n",
    "\n",
    "Before fitting the linear regression, we will find a simple null model for global food consumption data. To calculate the null model, we found the average of each predictor column in the Dataframe. This gives us a 'global average' of consumption of each predictor. We can then use the null model to establish a baseline $R^2$ that we will then improve upon using our linear regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LinearRegression as LinReg\n",
    "from sklearn.cross_validation import train_test_split as sk_split\n",
    "import statsmodels.api as sm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in initial dataframe\n",
    "x_df = pd.read_csv('predictors_filled_156.csv')\n",
    "\n",
    "# read in disease rates\n",
    "diabetes_df = pd.read_csv('diabetes_156.csv',index_col = 0)\n",
    "cardio_df = pd.read_csv('cardio_156.csv',index_col = 0)\n",
    "cancer_df= pd.read_csv('cancer_156.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Model testing:\n",
    "\n",
    "As expected, testing the null model on various training set give us a cross-validated $R^2$ of approximately zero for all three diseases. \n",
    "\n",
    "#### Cancer: \n",
    "The null model for cancer will always predict the mean cancer mortality rate. Testing on cancer, we get an $R^2$ of 3.33 E -16, which is ~ 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null Model Cancer\n",
    "null_model = LinReg()\n",
    "null_model.fit(x_df, [np.mean(cancer_df['Cancer Mortality Rate'])]*x_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Cancer.\n",
    "null_model.score(x_df, cancer_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diabetes\n",
    "Testing on diabetes, we also get an $R^2$ of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Diabetes Null Model\n",
    "null_model = LinReg()\n",
    "null_model.fit(x_df, [np.mean(diabetes_df['Diabetes Mortality Rate'])]*x_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Diabetes.\n",
    "null_model.score(x_df, diabetes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Cardiovascular Diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test cardiovascular diseases\n",
    "null_model = LinReg()\n",
    "null_model.fit(x_df, [np.mean(cardio_df['Cardio Mortality Rate'])]*x_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test cardiovascular diseases.\n",
    "null_model.score(x_df, cardio_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple LinReg\n",
    "\n",
    "## Cancer LinReg\n",
    "\n",
    "Now, we will fit a simple multi-linear regression to all of the food consumption inputs for each of the diseases. First, for cancer, our regression has an initial $R^2$ on the training set of .85, and a cross-validated $R^2$ of -16.5 for $k = 5$ folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r^2: 0.842393103733\n"
     ]
    }
   ],
   "source": [
    "linreg = LinReg()\n",
    "linreg.fit(x_df, cancer_df)\n",
    "print \"Training r^2:\",linreg.score(x_df, cancer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-30.410282842295079"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validated R-squared score\n",
    "np.mean(cross_val_score(LinReg(), x_df,cancer_df, cv = KFold(151, 5), scoring = \"r2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further examine the accuracy of this model, the map below displays the fractional difference of the model estimates as compared to the actual cancer data on a world map. As we can see, the vast majority of countries are colored a dark blue/ purple color, indicating they have a low fractional difference. Countries colored a brighter purple/pink color indicate an overestimate, while countries colored in a brighter blues indicate an underestimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PUT GRAPH HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Diabetes LinReg\n",
    "For diabetes, our regression has an initial cross-validated $R^2$ of ** PUT THE R^2 HERE**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2 0.807019987902\n",
      "CV R^2 score: -4.48569244044\n"
     ]
    }
   ],
   "source": [
    "linreg = LinReg()\n",
    "linreg.fit(x_df, diabetes_df)\n",
    "print \"Training R^2\", linreg.score(x_df, diabetes_df)\n",
    "\n",
    "# Cross-validated R^2 score for diabetes\n",
    "print \"CV R^2 score:\",np.mean(cross_val_score(LinReg(), x_df,diabetes_df, cv = KFold(5), scoring = \"r2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can examine a world map to see the fractional differences. Again, dark blue/purple colors indicate an accurate estimate,brighter purples/pinks indicate an overestimate, and brighter blues indicate an underestimate. We note thatthis model has slightly worse performance than our cancer model, which may have to do with the fact that diabetes does not lead to death as commonly as cancer does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cardiovascular Diseases LinReg\n",
    "For diabetes, our regression has an initial $R^2$ on the training set of .856, and a cross-validated $R^2$ of -6.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2 0.850938184461\n",
      "Cross-validated R^2 -5.2779763269\n"
     ]
    }
   ],
   "source": [
    "linreg = LinReg()\n",
    "linreg.fit(x_df, cardio_df)\n",
    "print \"Training R^2\", linreg.score(x_df, cardio_df)\n",
    "print \"Cross-validated R^2\", np.mean(cross_val_score(LinReg(), x_df,cardio_df, cv = KFold(151, 5), scoring = \"r2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can examine a world map to see the fractional differences. Dark blue/purple colors indicate an accurate estimate,brighter purples/pinks indicate an overestimate, and brighter blues indicate an underestimate. While this model appears to be fairly accurate for *THESE COUNTRIES*, it could be improved for *THESE*. This might be due to certain predictors, such as *SOME RANDOM PREDICTOR*, that is more heavily weighted for larger countries than for the country that is seeing a larger fractional difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "--- \n",
    "# Advanced Models \n",
    "***\n",
    "\n",
    "In this section, we will use various other regression techniques and variable selection techniques to attempt to improve upon our naive model. In particular, we will try \n",
    "\n",
    "1. Lasso\n",
    "2. PCA\n",
    "3. Regression Tree\n",
    "4. Step-wise Variable Selection\n",
    "\n",
    "For reference, our naive model gives us the following cross-validated $R^2$ values with $k = 5$: \n",
    "\n",
    "||Cardio | Diabetes | Cancer\n",
    "|--- | --- | --- | ---|\n",
    "|R^2 (Training)| .856 | .834 | .856|\n",
    "\n",
    "## Lasso\n",
    "\n",
    "The naive model brought up in the previous section has one major flaw: by including all of the predictors, it is very likely to be overfitted to the initial dataset. As such, we would like to reduce that overfitting by using variable selection techniques such as Lasso to reduce the number of predictors our model includes. \n",
    "Using the LassoCV package in sklearn, we obtain the following cross-validated $R^2$:\n",
    "\n",
    "| |Cardio   |  Diabetes | Cancer  |\n",
    "|-----|---|---|---|\n",
    "|$r^2$ (Lasso) |  .456 |  .31 |   .053|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a function we used to calculate the cross-validated r^2 for lasso over a number of folds for a certain parameter value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lasso_k_fold_r_squared(x_train, y_train, num_folds, param_val):\n",
    "    n_train = x_train.shape[0]\n",
    "    n = int(np.round(n_train * 1. / num_folds)) # points per fold\n",
    "\n",
    "    # Iterate over folds\n",
    "    cv_r_squared = 0\n",
    "    \n",
    "    for fold in range(1, num_folds + 1):\n",
    "        # Take k-1 folds for training \n",
    "        x_first_half = x_train.iloc[:n * (fold - 1), :]\n",
    "        x_second_half = x_train.iloc[n * fold + 1:, :]\n",
    "        x_train_cv = np.concatenate((x_first_half, x_second_half), axis=0)\n",
    "        \n",
    "        y_first_half = y_train.iloc[:n * (fold - 1)]\n",
    "        y_second_half = y_train.iloc[n * fold + 1:]\n",
    "        y_train_cv = np.concatenate((y_first_half, y_second_half), axis=0)\n",
    "        \n",
    "        # Take the middle fold for testing\n",
    "        x_test_cv = x_train.iloc[1 + n * (fold - 1):n * fold, :]\n",
    "        y_test_cv = y_train.iloc[1 + n * (fold - 1):n * fold]\n",
    "\n",
    "        # Fit Decision Tree model with parameter value on CV train set, and evaluate CV test performance\n",
    "        reg = Lasso(alpha = param_val, normalize=True)\n",
    "        reg.fit(x_train_cv, y_train_cv)\n",
    "        coefficients = reg.coef_\n",
    "        #print len([i for i, item in enumerate(coefficients) if abs(item) >0])\n",
    "        r_squared = reg.score(x_test_cv, y_test_cv)\n",
    "    \n",
    "        # Cummulative R^2 value across folds\n",
    "        cv_r_squared += r_squared\n",
    "\n",
    "    # Return average R^2 value across folds\n",
    "    return cv_r_squared * 1.0 / num_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cancer\n",
    "\n",
    "Running Lasso on different values of alpha yields a top cross-validated $r^2$ score of .059, for alpha = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO\n",
      "cancer 0.001 -10.0863952587\n",
      "cancer 0.01 -2.62319418962\n",
      "cancer 0.1 -0.189052791559\n",
      "cancer 0.4 0.15663394152\n",
      "cancer 0.5 0.13439828752\n",
      "cancer 0.6 0.117227909906\n",
      "cancer 1 0.0530720050382\n",
      "cancer 5 -0.0745935162681\n",
      "cancer 10 -0.0745935162681\n",
      "cancer 100 -0.0745935162681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "print \"LASSO\"\n",
    "for alpha in [.001, .01, .1,.4,.5,.6,1,5,10,100]:\n",
    "    print \"cancer\",alpha, lasso_k_fold_r_squared(x_df,cancer_df,5, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cardiovascular Diseases\n",
    "Running Lasso on different values of alpha yields a top cross-validated $r^2$ score of .459, for alpha = .9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO\n",
      "cardio 0.001 -5.42791396765\n",
      "cardio 0.1 -0.111196584756\n",
      "cardio 0.5 0.415841480013\n",
      "cardio 0.8 0.451848911048\n",
      "cardio 0.9 0.455639379888\n",
      "cardio 1 0.456181146633\n",
      "cardio 2 0.404302118408\n",
      "cardio 5 0.0132238574549\n",
      "cardio 10 -0.010213535932\n",
      "cardio 100 -0.010213535932\n",
      "cardio 1000 -0.010213535932\n"
     ]
    }
   ],
   "source": [
    "print \"LASSO\"\n",
    "for alpha in [.001, .1, .5,.8, .9, 1, 2,5, 10, 100, 1000]:\n",
    "    print \"cardio\",alpha, lasso_k_fold_r_squared(x_df,cardio_df,5, alpha)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1, copy_X=True, fit_intercept=True, max_iter=1000, normalize=True,\n",
       "   positive=False, precompute=False, random_state=None, selection='cyclic',\n",
       "   tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = Lasso(alpha = 1, normalize=True)\n",
    "reg.fit(x_df, cardio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes \n",
    "Running Lasso on different values of alpha from .001 to 100 yields a top cross-validated $r^2$ score of .29, for alpha = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASSO\n",
      "diabetes 0.001 -11.0600616776\n",
      "diabetes 0.01 -7.15802252011\n",
      "diabetes 0.05 -2.82047154641\n",
      "diabetes 0.1 -1.89295319289\n",
      "diabetes 0.5 -0.634815280625\n",
      "diabetes 1 -0.151038370671\n",
      "diabetes 10 0.309595435793\n",
      "diabetes 100 0.243569859518\n"
     ]
    }
   ],
   "source": [
    "print \"LASSO\"\n",
    "for alpha in [.001, .01, .05, .1, .5, 1, 10, 100]:\n",
    "    print \"diabetes\",alpha, lasso_k_fold_r_squared(x_df,diabetes_df,4, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge \n",
    "\n",
    "Again, in this section we'd like to try to use Ridge regression to improve the cross-validated $r^2$ for our model and reduce overfitting of the model.\n",
    "Below is a function we used to calculate the cross-validated r^2 for ridge regression over a number of folds for a certain parameter value.\n",
    "\n",
    "To summarize, we have:\n",
    "\n",
    "\n",
    "| |Cardio   |  Diabetes | Cancer  |\n",
    "|-----|---|---|---|\n",
    "|$r^2$ (Ridge) |  .424 |  .323 |   .168|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "def ridge_k_fold_r_squared(x_train, y_train, num_folds, param_val):\n",
    "    n_train = x_train.shape[0]\n",
    "    n = int(np.round(n_train * 1. / num_folds)) # points per fold\n",
    "\n",
    "    # Iterate over folds\n",
    "    cv_r_squared = 0\n",
    "    \n",
    "    for fold in range(1, num_folds + 1):\n",
    "        # Take k-1 folds for training \n",
    "        x_first_half = x_train.iloc[:n * (fold - 1), :]\n",
    "        x_second_half = x_train.iloc[n * fold + 1:, :]\n",
    "        x_train_cv = np.concatenate((x_first_half, x_second_half), axis=0)\n",
    "        \n",
    "        y_first_half = y_train.iloc[:n * (fold - 1)]\n",
    "        y_second_half = y_train.iloc[n * fold + 1:]\n",
    "        y_train_cv = np.concatenate((y_first_half, y_second_half), axis=0)\n",
    "        \n",
    "        # Take the middle fold for testing\n",
    "        x_test_cv = x_train.iloc[1 + n * (fold - 1):n * fold, :]\n",
    "        y_test_cv = y_train.iloc[1 + n * (fold - 1):n * fold]\n",
    "\n",
    "        # Fit Decision Tree model with parameter value on CV train set, and evaluate CV test performance\n",
    "        reg = Ridge(alpha = param_val, normalize=True)\n",
    "        reg.fit(x_train_cv, y_train_cv)\n",
    "        r_squared = reg.score(x_test_cv, y_test_cv)\n",
    "    \n",
    "        # Cummulative R^2 value across folds\n",
    "        cv_r_squared += r_squared\n",
    "\n",
    "    # Return average R^2 value across folds\n",
    "    return cv_r_squared * 1.0 / num_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cardiovascular Diseases\n",
    "Running Ridge regression on different values of alpha from .001 to 100 yields a top cross-validated $r^2$ score of .425, for alpha = 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIDGE\n",
      "cardio 0.001 -4.9919143728\n",
      "cardio 0.01 -2.75443505612\n",
      "cardio 0.1 -0.175066648391\n",
      "cardio 0.9 0.404437744071\n",
      "cardio 1 0.410643001\n",
      "cardio 1.1 0.415244083252\n",
      "cardio 1.3 0.421038145156\n",
      "cardio 1.5 0.423729737401\n",
      "cardio 1.9 0.423597298657\n",
      "cardio 5 0.36475407367\n",
      "cardio 10 0.27837000173\n",
      "cardio 11 0.265254747482\n",
      "cardio 100 0.0444563936422\n"
     ]
    }
   ],
   "source": [
    "print \"RIDGE\"\n",
    "for alpha in [.001, .01, .1, .9,1,1.1,1.3,1.5,1.9,5, 10, 11, 100]:\n",
    "    print \"cardio\",alpha, ridge_k_fold_r_squared(x_df,cardio_df,5, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes\n",
    "\n",
    "Running Lasso on different values of alpha from .001 to 100 yields a top cross-validated $r^2$ score of .317, for alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIDGE\n",
      "diabetes 0.001 -9.77735177572\n",
      "diabetes 0.01 -3.76622924788\n",
      "diabetes 0.1 -0.279553857695\n",
      "diabetes 0.9 0.314979301771\n",
      "diabetes 1 0.321214840769\n",
      "diabetes 3 0.325946173079\n",
      "diabetes 5 0.300072240351\n",
      "diabetes 10 0.246363686822\n",
      "diabetes 100 0.0540094335668\n",
      "diabetes 1000 -0.00498501391727\n"
     ]
    }
   ],
   "source": [
    "print \"RIDGE\"\n",
    "for alpha in [.001, .01, .1, .9,1,3, 5, 10,100, 1000]:\n",
    "    print \"diabetes\",alpha, ridge_k_fold_r_squared(x_df,diabetes_df,4, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None, normalize=True,\n",
       "   random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = Ridge(alpha = 1, normalize=True)\n",
    "reg.fit(x_df, diabetes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cancer\n",
    "\n",
    "Running Lasso on different values of alpha from .001 to 100 yields a top cross-validated $r^2$ score of .18, for alpha = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIDGE\n",
      "cancer 0.001 -9.11931708715\n",
      "cancer 0.01 -3.21130503559\n",
      "cancer 0.1 -0.681543066623\n",
      "cancer 1 0.0574910468362\n",
      "cancer 3 0.162757999505\n",
      "cancer 4 0.168501040516\n",
      "cancer 5 0.168009123824\n",
      "cancer 6 0.164780179616\n",
      "cancer 10 0.144581726236\n",
      "cancer 20 0.0992315721652\n",
      "cancer 1000 -0.0668769303926\n"
     ]
    }
   ],
   "source": [
    "print \"RIDGE\"\n",
    "\n",
    "for alpha in [.001, .01, .1, 1, 3, 4,5,10, 20, 1000]:\n",
    "    print \"cancer\",alpha, ridge_k_fold_r_squared(x_df,cancer_df,5, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Regression Trees\n",
    "---\n",
    "\n",
    "In this section, we'll try regression trees to see if they improve our model.\n",
    "\n",
    "Below, we have a function that we'll use to find the $r^2$ value for a given number of folds and certain hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "def rtree_k_fold_r_squared(x_train, y_train, num_folds, param_val):\n",
    "    n_train = x_train.shape[0]\n",
    "    n = int(np.round(n_train * 1. / num_folds)) # points per fold\n",
    "\n",
    "    # Iterate over folds\n",
    "    cv_r_squared = 0\n",
    "    \n",
    "    for fold in range(1, num_folds + 1):\n",
    "        # Take k-1 folds for training \n",
    "        x_first_half = x_train.iloc[:n * (fold - 1), :]\n",
    "        x_second_half = x_train.iloc[n * fold + 1:, :]\n",
    "        x_train_cv = np.concatenate((x_first_half, x_second_half), axis=0)\n",
    "        \n",
    "        y_first_half = y_train.iloc[:n * (fold - 1)]\n",
    "        y_second_half = y_train.iloc[n * fold + 1:]\n",
    "        y_train_cv = np.concatenate((y_first_half, y_second_half), axis=0)\n",
    "        \n",
    "        # Take the middle fold for testing\n",
    "        x_test_cv = x_train.iloc[1 + n * (fold - 1):n * fold, :]\n",
    "        y_test_cv = y_train.iloc[1 + n * (fold - 1):n * fold]\n",
    "\n",
    "        # Fit Decision Tree model with parameter value on CV train set, and evaluate CV test performance\n",
    "        reg = DecisionTreeRegressor(max_depth=param_val)\n",
    "        reg.fit(x_train_cv, y_train_cv)\n",
    "        r_squared = reg.score(x_test_cv, y_test_cv)\n",
    "    \n",
    "        # Cummulative R^2 value across folds\n",
    "        cv_r_squared += r_squared\n",
    "\n",
    "    # Return average R^2 value across folds\n",
    "    return cv_r_squared * 1.0 / num_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cardiovascular Diseases\n",
    "\n",
    "For cardiovascular diseases, we see the best $r^2 = .44$ for max_depth = 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.424335403226\n",
      "3 0.313078907323\n",
      "4 0.230103986075\n",
      "5 0.154881054117\n",
      "10 0.0746420574928\n",
      "50 0.217683941889\n",
      "100 0.0820025125761\n"
     ]
    }
   ],
   "source": [
    "for depth in [2, 3, 4, 5, 10, 50, 100]:\n",
    "    print depth, rtree_k_fold_r_squared(x_df,cardio_df,5, depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes\n",
    "\n",
    "For diabetes, we see the best $r^2$ of $.157$ for a max-depth of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.135877261593\n",
      "3 0.0669070393589\n",
      "4 -0.0048575681988\n",
      "5 0.0545434405144\n",
      "10 -0.150080332407\n",
      "50 -0.299664889236\n",
      "100 -0.305172491679\n"
     ]
    }
   ],
   "source": [
    "for depth in [2, 3, 4, 5, 10, 50, 100]:\n",
    "    print depth, rtree_k_fold_r_squared(x_df,diabetes_df,5, depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cancer\n",
    "\n",
    "All of the $r^2$ for decision trees on cancer were negative, indicating that these actually perform worse than the null model and as such are not useful models to examine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 -0.908504830182\n",
      "3 -0.914686106965\n",
      "5 -1.02371038451\n",
      "8 -1.17331433126\n",
      "9 -0.92569309602\n",
      "10 -1.11543087937\n",
      "20 -1.41288087569\n",
      "50 -1.3521432352\n",
      "70 -0.972645342176\n",
      "100 -1.15913214825\n"
     ]
    }
   ],
   "source": [
    "for depth in [2, 3, 5, 8, 9, 10, 20, 50, 70, 100]:\n",
    "    print depth, rtree_k_fold_r_squared(x_df,cancer_df,5, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
